{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from talib import RSI, BBANDS, MACD, NATR, ATR\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "DATA_STORE = Path('sp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P 500 Bestandteile und Änderungen am Index von Wikipedia beziehen\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "table_constituents = soup.find(\"table\", {\"id\": \"constituents\"})\n",
    "table_changes = soup.find(\"table\", {\"id\": \"changes\"})\n",
    "\n",
    "constituents_df = pd.read_html(str(table_constituents))[0]\n",
    "changes_df = pd.read_html(str(table_changes))[0].dropna()\n",
    "print(constituents_df.info())\n",
    "print(changes_df.info())\n",
    "\n",
    "print(changes_df)\n",
    "print(constituents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P500 Monatliche Bestandteile\n",
    "monthly_constituents = pd.DataFrame(columns=['Date', 'Constituents'])\n",
    "current_constituents = set(constituents_df['Symbol'].unique())\n",
    "print(current_constituents)\n",
    "current_date = datetime.today()\n",
    "previous_month_end = current_date.replace(day=1) - pd.Timedelta(days=1)\n",
    "date_range = pd.date_range(start='2010-01-01', end=previous_month_end, freq='M')\n",
    "date_range = date_range[::-1]\n",
    "\n",
    "monthly_constituents = monthly_constituents.append({'Date': current_date, 'Constituents': current_constituents.copy()}, ignore_index=True)\n",
    "for date in date_range:\n",
    "    for index, row in changes_df.iterrows():\n",
    "        change_month = pd.to_datetime(row['Date']).dt.month.item()\n",
    "        change_year = pd.to_datetime(row['Date']).dt.year.item()\n",
    "        if (change_year == date.year and change_month == date.month):\n",
    "            current_constituents.discard(row['Added']['Ticker'])\n",
    "            current_constituents.add(row['Removed']['Ticker'])\n",
    "    print(current_constituents)\n",
    "    monthly_constituents = monthly_constituents.append({'Date': date, 'Constituents': current_constituents.copy()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('monatliche_bestandteile', monthly_constituents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    a = store.get('monatliche_bestandteile')['Constituents']\n",
    "    print(a.info())\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    a = store.get('monatliche_bestandteile')['Constituents']\n",
    "    print(a.describe())\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "\n",
    "    tickers = store.get('monatliche_bestandteile')['Constituents']\n",
    "    all_tickers = list()\n",
    "    for ticker_set in tickers:\n",
    "        all_tickers.append(ticker_set)\n",
    "    res = set().union(*all_tickers)\n",
    "    print(res)\n",
    "    print(len(res))\n",
    "\n",
    "    store.put('all_tickers', pd.Series(list(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA_VANTAGE_API_KEY = 'SINNAMIDDPGINMN0'\n",
    "\n",
    "# Historische Kursdaten von Alpha Vantage abrufen\n",
    "def get_historical_data(symbol):\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_WEEKLY_ADJUSTED&symbol={symbol}&apikey={ALPHA_VANTAGE_API_KEY}&outputsize=full'\n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "    print(str(response))\n",
    "    error = False\n",
    "    if (str(response).startswith(\"{'Error Message'\")):\n",
    "        error = True\n",
    "        print(symbol)\n",
    "    if (error):\n",
    "        return pd.DataFrame()\n",
    "    json_data = response['Weekly Adjusted Time Series']\n",
    "\n",
    "    data = []\n",
    "    for date, values in json_data.items():\n",
    "        data.append({\n",
    "            'date': date,\n",
    "            'open': float(values['1. open']),\n",
    "            'high': float(values['2. high']),\n",
    "            'low': float(values['3. low']),\n",
    "            'close': float(values['4. close']),\n",
    "            'adjusted_close': float(values['5. adjusted close']),\n",
    "            'volume': int(values['6. volume'])\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ticker ausgeben, für die kein abruf möglich war\n",
    "# #ticker anzahl ausgeben, für die kein abruf möglich war\n",
    "\n",
    "# failed_requests = 0\n",
    "# failed_tickers = []\n",
    "\n",
    "# with pd.HDFStore(DATA_STORE) as store:\n",
    "#     tickers = store.get('all_tickers')\n",
    "#     df = pd.DataFrame(columns=['prices'])\n",
    "#     i = 1\n",
    "#     for ticker in tickers:\n",
    "#         if (i % 75 == 0):\n",
    "#             sleep(70)\n",
    "#         try:\n",
    "#             data = get_historical_data(ticker)\n",
    "#             df.loc[ticker] = {'prices': data}\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to retrieve data for ticker {ticker}: {e}\")\n",
    "#             failed_requests += 1\n",
    "#             failed_tickers.append(ticker)\n",
    "#         i += 1\n",
    "#     store.put('historical_prices', df)\n",
    "\n",
    "# print(f\"Failed requests: {failed_requests}\")\n",
    "# print(f\"Failed tickers: {failed_tickers}\")\n",
    "\n",
    "# #count funktion geht hier nicht\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialisiere die Fehlerzähler\n",
    "# failed_requests = 0\n",
    "# failed_tickers = []\n",
    "\n",
    "# # Funktion, um zählen zu ermöglichen\n",
    "# class ApiError(Exception):\n",
    "#     pass\n",
    "\n",
    "# with pd.HDFStore(DATA_STORE) as store:\n",
    "#     tickers = store.get('all_tickers')\n",
    "#     df = pd.DataFrame(columns=['prices'])\n",
    "#     i = 1\n",
    "#     for ticker in tickers:\n",
    "#         if (i % 75 == 0):\n",
    "#             sleep(70)\n",
    "#         try:\n",
    "#             data = get_historical_data(ticker)\n",
    "#             if \"Error Message\" in data:\n",
    "#                 raise ApiError(\"API error\")\n",
    "#             df.loc[ticker] = {'prices': data}\n",
    "#         except ApiError as e:\n",
    "#             print(f\"Failed to retrieve data for ticker {ticker}: {e}\")\n",
    "#             failed_requests += 1\n",
    "#             failed_tickers.append(ticker)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Unexpected error for ticker {ticker}: {e}\")\n",
    "#         else:\n",
    "#             i += 1\n",
    "#     store.put('historical_prices', df)\n",
    "\n",
    "# print(f\"Failed requests: {failed_requests}\")\n",
    "# print(f\"Failed tickers: {failed_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere die Fehlerzähler\n",
    "failed_requests = 0\n",
    "failed_tickers = []\n",
    "\n",
    "# Funktion, um zählen zu ermöglichen\n",
    "class ApiError(Exception):\n",
    "    pass\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    tickers = store.get('all_tickers')\n",
    "    df = pd.DataFrame(columns=['prices'])\n",
    "    i = 1\n",
    "    for ticker in tickers:\n",
    "        if (i % 75 == 0):\n",
    "            sleep(70)\n",
    "        try:\n",
    "            data = get_historical_data(ticker)\n",
    "            if \"Error Message\" in data:\n",
    "                raise ApiError(\"API error\")\n",
    "            df.loc[ticker] = {'prices': data}\n",
    "        except ApiError as e:\n",
    "            print(f\"Failed to retrieve data for ticker {ticker}: {e}\")\n",
    "            failed_requests += 1\n",
    "            failed_tickers.append(ticker)\n",
    "        except Exception as e:\n",
    "            print(f\" error for {ticker}: {e}\")\n",
    "        i += 1\n",
    "    store.put('historical_prices', df)\n",
    "#Fehlerzählen geht nicht\n",
    "print(f\"Failed requests: {failed_requests}\")\n",
    "print(f\"Failed tickers: {failed_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mit fehlerzähler\n",
    "# # Initialisiere die Fehlerzähler\n",
    "# failed_requests = 0\n",
    "# failed_tickers = []\n",
    "\n",
    "# # Funktion, um Fehler zählen zu ermöglichen; Zählen funktioniert leider nicht; Aber Symbole\n",
    "# class ApiError(Exception):\n",
    "#     pass\n",
    "\n",
    "# with pd.HDFStore(DATA_STORE) as store:\n",
    "#     tickers = store.get('all_tickers')\n",
    "#     df = pd.DataFrame(columns=['prices'])\n",
    "#     i = 1\n",
    "#     for ticker in tickers:\n",
    "#         if (i % 75 == 0):\n",
    "#             sleep(70)\n",
    "#         try:\n",
    "#             data = get_historical_data(ticker)\n",
    "#             if \"Error Message\" in data:\n",
    "#                 raise ApiError(\"API error\")\n",
    "#             df.loc[ticker] = {'prices': data}\n",
    "#         except ApiError as e:\n",
    "#             print(f\"Failed to retrieve data for ticker {ticker}: {e}\")\n",
    "#             failed_requests += 1\n",
    "#             failed_tickers.append(ticker)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Unexpected error for ticker {ticker}: {e}\")\n",
    "#         i += 1\n",
    "#     store.put('historical_prices', df)\n",
    "\n",
    "# print(f\"Failed requests: {failed_requests}\")\n",
    "# print(f\"Failed tickers: {failed_tickers}\")\n",
    "# print(f\"Failed tickers: {len(failed_tickers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    prices = store.get('historical_prices')\n",
    "    print(prices.loc['XLNX']['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Berechnung Beta mit yfinance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import yfinance as yf\n",
    "\n",
    "# Funktion zum Abrufen von monatlichen Preisdaten\n",
    "def get_monthly_data(ticker):\n",
    "    data = yf.download(ticker, start=\"2000-01-01\", end=\"2023-04-02\", interval=\"1mo\")\n",
    "    data = data.dropna()\n",
    "    data = data[\"Adj Close\"]\n",
    "    return data\n",
    "\n",
    "# Daten für Apple (AAPL) und S&P 500 Index (^GSPC) abrufen -> bei yfinance ist Abruf GSPC möglich\n",
    "ticker_data = get_monthly_data(\"AAPL\")\n",
    "sp500_data = get_monthly_data(\"^GSPC\")\n",
    "\n",
    "# Monatliche Renditen berechnen\n",
    "stock_returns = ticker_data.pct_change().dropna()\n",
    "sp500_returns = sp500_data.pct_change().dropna()\n",
    "\n",
    "# Rollierende Regression\n",
    "window_size = 60  # 5 Jahre (12 Monate * 5 Jahre)\n",
    "rolling_betas = []\n",
    "rolling_dates = []\n",
    "\n",
    "for i in range(len(stock_returns) - window_size + 1):\n",
    "    y = stock_returns.iloc[i:i+window_size]\n",
    "    X = sp500_returns.iloc[i:i+window_size]\n",
    "    X = sm.add_constant(X)  # Konstante, um den Alpha-Koeffizienten zu schätzen\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    beta = model.params[\"Adj Close\"]\n",
    "    rolling_betas.append(beta)\n",
    "    rolling_dates.append(y.index[-1])\n",
    "\n",
    "rolling_betas = pd.Series(rolling_betas, index=rolling_dates)\n",
    "\n",
    "print(rolling_betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIER NOCH VERGLEICH DER ABRUFE DURCH Y FINANCE FAILED\n",
    "zeitraum ist extra länger eingestellt als bei wikipedia, weil für beta berechnung z.b. historische daten von vorher benötigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yfinance liefert trotz beschränkung des Zeitraums für 99 Ticker keine Daten\n",
    "\n",
    "# import yfinance as yf\n",
    "\n",
    "# def get_historical_data_yf(ticker, start_date='2010-01-01', end_date=None):\n",
    "#     if end_date is None:\n",
    "#         end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "#     try:\n",
    "#         stock_data = yf.download(ticker, start=start_date, end=end_date, interval='1wk', auto_adjust=True)\n",
    "#         return stock_data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching data for {ticker}: {e}\")\n",
    "#         return pd.DataFrame()\n",
    "# failed_requests = 0\n",
    "# failed_tickers = []\n",
    "\n",
    "# with pd.HDFStore(DATA_STORE) as store:\n",
    "#     tickers = store.get('all_tickers')\n",
    "#     df = pd.DataFrame()\n",
    "\n",
    "#     for ticker in tickers:\n",
    "#         data = get_historical_data_yf(ticker)\n",
    "#         if data.empty:\n",
    "#             failed_requests += 1\n",
    "#             failed_tickers.append(ticker)\n",
    "#         else:\n",
    "#             data['ticker'] = ticker\n",
    "#             df = df.append(data)\n",
    "\n",
    "#     store.put('historical_prices_yf', df)\n",
    "\n",
    "# print(f\"Failed requests: {failed_requests}\")\n",
    "# print(f\"Failed tickers: {failed_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "\n",
    "# class YFinanceError(Exception):\n",
    "#     pass\n",
    "\n",
    "# def get_yfinance_data(ticker):\n",
    "#     try:\n",
    "#         data = yf.download(ticker, start=\"2000-01-01\", end=\"2023-04-02\", interval=\"1wk\")\n",
    "#         data = data.dropna()\n",
    "#         data = data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "#         if data.empty:\n",
    "#             raise YFinanceError(\"No data found\")\n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to retrieve data for ticker {ticker}: {e}\")\n",
    "#         raise YFinanceError(\"Failed to download\")\n",
    "\n",
    "# failed_requests = 0\n",
    "# failed_tickers = []\n",
    "\n",
    "# with pd.HDFStore(DATA_STORE) as store:\n",
    "#     tickers = store.get('all_tickers')\n",
    "#     df = pd.DataFrame(columns=['prices'])\n",
    "#     i = 1\n",
    "#     for ticker in tickers:\n",
    "#         try:\n",
    "#             data = get_yfinance_data(ticker)\n",
    "#             df.loc[ticker] = {'prices': data}\n",
    "#         except YFinanceError as e:\n",
    "#             failed_requests += 1\n",
    "#             failed_tickers.append(ticker)\n",
    "#         i += 1\n",
    "#     store.put('historical_prices_yf', df)\n",
    "\n",
    "# print(f\"Failed requests: {failed_requests}\")\n",
    "# print(f\"Failed tickers: {failed_tickers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = 'SINNAMIDDPGINMN0'\n",
    "\n",
    "# Hinzufügen von Fehlerzählern\n",
    "fetch_errors = 0\n",
    "calc_errors = 0\n",
    "\n",
    "#   Abrufen von monatlichen Zeitreihendaten\n",
    "def get_monthly_data(symbol, api_key):\n",
    "    global fetch_errors  # Zugriff auf globale Variable fetch_errors\n",
    "\n",
    "    base_url = \"https://www.alphavantage.co/query\"\n",
    "    function = \"TIME_SERIES_MONTHLY_ADJUSTED\"\n",
    "    outputsize = \"full\"\n",
    "    datatype = \"json\"\n",
    "\n",
    "    params = {\n",
    "        \"function\": function,\n",
    "        \"symbol\": symbol,\n",
    "        \"apikey\": api_key,\n",
    "        \"outputsize\": outputsize,\n",
    "        \"datatype\": datatype\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if \"Error Message\" in data:\n",
    "        print(\"Fehler bei Datenabruf für \" + symbol)\n",
    "        fetch_errors += 1  # Fehlerzähler für den Abruf erhöhen\n",
    "\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data[\"Monthly Adjusted Time Series\"]).T\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    df = df[\"5. adjusted close\"].astype(float)\n",
    "\n",
    "    return df\n",
    "\n",
    "stock_list = []\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    tickers = store.get('all_tickers')\n",
    "    for ticker in tickers:\n",
    "        stock_list.append(ticker)\n",
    "\n",
    "sp500_data = get_monthly_data(\"SPY\", api_key) #Spy ETF statt Index\n",
    "betas = pd.DataFrame(columns=['ticker', 'rolling_betas'])\n",
    "\n",
    "for ticker in stock_list:\n",
    "\n",
    "    try:\n",
    "        # Daten für Aktien und S&P 500 ETF (SPY) abrufen\n",
    "        ticker_data = get_monthly_data(ticker, api_key)\n",
    "\n",
    "        # Startdatum auf den späteren Start von Aktien oder SPY setzen\n",
    "        start_date = max(ticker_data.index.min(), sp500_data.index.min())\n",
    "\n",
    "        # Daten auf gemeinsamen Zeitraum beschränken\n",
    "        ticker_data = ticker_data[start_date:]\n",
    "        sp500_data_last = sp500_data[start_date:]\n",
    "\n",
    "        # Monatliche Renditen berechnen\n",
    "        meta_returns = ticker_data.pct_change().dropna()\n",
    "        sp500_returns = sp500_data_last.pct_change().dropna()\n",
    "\n",
    "        # Rollierende Regression für 5 Jahres Beta\n",
    "        window_size = 60  # 5 Jahre (12 Monate * 5 Jahre)\n",
    "        rolling_betas = []\n",
    "        rolling_dates = []\n",
    "\n",
    "        for i in range(len(meta_returns) - window_size + 1):\n",
    "            y = meta_returns.iloc[i:i+window_size]\n",
    "            X = sp500_returns.iloc[i:i+window_size]\n",
    "            X = sm.add_constant(X)  # Schätzen des Alpha-Koeffizienten\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            beta = model.params[\"5. adjusted close\"]\n",
    "            rolling_betas.append(beta)\n",
    "            rolling_dates.append(y.index[-1])\n",
    "    except:\n",
    "        print(\"Fehler bei Berechnung des Betas für \" + ticker)\n",
    "        calc_errors += 1  # Fehlerzähler für die Berechnung erhöhen\n",
    "\n",
    "    rolling_betas = pd.Series(rolling_betas, index=rolling_dates)\n",
    "    betas = betas.append({'ticker': ticker, 'rolling_betas': rolling_betas}, ignore_index=True)\n",
    "\n",
    "    print(f\"Fehler beim Abrufen der Daten: {fetch_errors}\")\n",
    "    print(f\"Fehler bei der Berechnung der Beta-Werte: {calc_errors}\")\n",
    "#Zählen der Fehler beim Abruf + bei Berechnung der Beta Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #alternativ\n",
    "# for ticker in stock_list:\n",
    "#     try:\n",
    "#         # Daten für Aktien und S&P 500 ETF (SPY) abrufen\n",
    "#         ticker_data = get_monthly_data(ticker, api_key)\n",
    "#     except:\n",
    "#         print(\"Fehler beim Abrufen der Daten für \" + ticker)\n",
    "#         fetch_errors += 1\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         # Startdatum auf den späteren Start von Aktien oder SPY setzen\n",
    "#         start_date = max(ticker_data.index.min(), sp500_data.index.min())\n",
    "\n",
    "#         # Daten auf gemeinsamen Zeitraum beschränken\n",
    "#         ticker_data = ticker_data[start_date:]\n",
    "#         sp500_data_last = sp500_data[start_date:]\n",
    "\n",
    "#         # Monatliche Renditen berechnen\n",
    "#         meta_returns = ticker_data.pct_change().dropna()\n",
    "#         sp500_returns = sp500_data_last.pct_change().dropna()\n",
    "\n",
    "#         # Rollierende Regression für 5 Jahres Beta\n",
    "#         window_size = 60  # 5 Jahre (12 Monate * 5 Jahre)\n",
    "#         rolling_betas = []\n",
    "#         rolling_dates = []\n",
    "\n",
    "#         for i in range(len(meta_returns) - window_size + 1):\n",
    "#             y = meta_returns.iloc[i:i+window_size]\n",
    "#             X = sp500_returns.iloc[i:i+window_size]\n",
    "#             X = sm.add_constant(X)  # Schätzen des Alpha-Koeffizienten\n",
    "#             model = sm.OLS(y, X).fit()\n",
    "#             beta = model.params[\"5. adjusted close\"]\n",
    "#             rolling_betas.append(beta)\n",
    "#             rolling_dates.append(y.index[-1])\n",
    "\n",
    "#         rolling_betas = pd.Series(rolling_betas, index=rolling_dates)\n",
    "#         betas = betas.append({'ticker': ticker, 'rolling_betas': rolling_betas}, ignore_index=True)\n",
    "#     except:\n",
    "#         print(\"Fehler bei Berechnung des Betas für \" + ticker)\n",
    "#         calc_errors += 1\n",
    "\n",
    "# print(f\"Fehler beim Abrufen der Daten: {fetch_errors}\")\n",
    "# print(f\"Fehler bei der Berechnung der Beta-Werte: {calc_errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(betas.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('betas', betas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zusammenfügen der errechneten Beta Werte mit dem Datenset\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    prices = store.get('historical_prices')\n",
    "    betas = store.get('betas').set_index('ticker')\n",
    "    for index, row in betas.iterrows():\n",
    "        merge_prices = prices.loc[index]['prices'].set_index('date')\n",
    "        merge_prices.index = pd.to_datetime(merge_prices.index)\n",
    "        row.index = pd.to_datetime(row.index)\n",
    "        merged = pd.merge_asof(merge_prices, row, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    prices = store.get('historical_prices')\n",
    "    betas = store.get('betas').set_index('ticker')\n",
    "    prices_merged = prices.copy()\n",
    "    for ticker in prices.index.values:\n",
    "        print(ticker)\n",
    "        merge_betas = betas.loc[ticker]['rolling_betas'].rename('betas')\n",
    "        if (not merge_betas.empty):\n",
    "            try:\n",
    "                merge_prices = prices.loc[ticker]['prices'].set_index('date')\n",
    "                merge_prices.index = pd.to_datetime(merge_prices.index)\n",
    "                merge_prices = merge_prices.sort_index()\n",
    "                merged = pd.merge_asof(merge_prices, merge_betas, left_on='date', right_index=True)\n",
    "                prices_merged.loc[ticker]['prices'] = merged\n",
    "            except:\n",
    "                print(\"failed: \" + ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = prices_merged.loc['META']['prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged.iloc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.loc['AAPL'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Beta für bestimmte Aktie\n",
    "betas.iloc[561]['rolling_betas'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Erstellen eines Plots für den Beta-Wert von Apple\n",
    "betas.iloc[561]['rolling_betas'].plot()\n",
    "\n",
    "# Festlegen des Zeitbereichs \n",
    "plt.xlim([datetime.date(2012, 1, 1), datetime.date(2023, 1, 8)])\n",
    "\n",
    "# Festlegen des Wertebereichs für die y-Achse auf 0,8 bis 1,4\n",
    "plt.ylim([0.7, 1.4])\n",
    "\n",
    "# Anzeigen des Plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index, row in betas.iterrows():\n",
    "    if (row['rolling_betas'].empty):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    print(store.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `prices_merged` DataFrame im HDFStore speichern\n",
    "with pd.HDFStore(DATA_STORE, mode='a') as store:\n",
    "    store.put('prices_merged', prices_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    data = store.get('prices_merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(monthly_constituents.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Anzahl an Bestandteilen im Zeitverlauf\n",
    "monthly_constituents['Num_Constituents'] = monthly_constituents['Constituents'].apply(len)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "monthly_constituents['Num_Constituents'].plot(figsize=(10, 5))\n",
    "plt.title(\"Anzahl der S&P 500 Aktien im Laufe der Zeit\")\n",
    "plt.ylabel(\"Anzahl der Aktien\")\n",
    "plt.xlabel(\"Datum\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wann war welche Aktie im S&P500\n",
    "def get_sp500_tickers_on_date(date, monthly_constituents):\n",
    "    tickers_on_date = None\n",
    "    for idx, row in monthly_constituents.iterrows():\n",
    "        if row['Date'] <= date:\n",
    "            tickers_on_date = row['Constituents']\n",
    "            break\n",
    "    return tickers_on_date\n",
    "\n",
    "\n",
    "monthly_constituents_df = pd.DataFrame(columns=['Date', 'Constituents'])\n",
    "\n",
    "start_date = '2009-01-01'\n",
    "end_date = '2023-12-31'\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "for date in date_range:\n",
    "    tickers_on_date = get_sp500_tickers_on_date(date, monthly_constituents)\n",
    "    monthly_constituents_df = monthly_constituents_df.append({'Date': date, 'Constituents': tickers_on_date}, ignore_index=True)\n",
    "\n",
    "# Speichern des DataFrame im HDFStore\n",
    "DATA_STORE = 'sp.h5'\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('monthly_constituents', monthly_constituents_df)\n",
    "    monthly_constituents_backtest_df = monthly_constituents_df\n",
    "\n",
    "    store.put('monthly_constituents_backtest', monthly_constituents_backtest_df)\n",
    "\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    print(store.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_constituents.set_index('Date', inplace=True)\n",
    "\n",
    "# Visualisierung der Anzahl an Bestandteilen im Zeitverlauf\n",
    "monthly_constituents['Num_Constituents'] = monthly_constituents['Constituents'].apply(len)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "monthly_constituents['Num_Constituents'].plot(figsize=(10, 5))\n",
    "plt.title(\"Anzahl der S&P 500 Aktien im Laufe der Zeit\")\n",
    "plt.ylabel(\"Anzahl der Aktien\")\n",
    "plt.xlabel(\"Datum\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e620c9bab6bccb53d6d9ffc4dd9967897e150d5f2be1ad9171ded01cbc6a4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
